Traditional educational methods often struggle to convey complex, spatial, and dynamic concepts such as those found in orbital mechanics. The recent convergence of consumer-grade Augmented Reality (AR) and sophisticated Generative AI agents presents an opportunity to create a new paradigm for intuitive and experiential learning interfaces. This paper details the design, development, and evaluation of an interactive educational platform for exploring the principles of orbital mechanics. The system's primary objective is to bridge the gap between abstract physical laws and intuitive comprehension by enabling users to learn through embodied interaction. The methodology is centered on a modular architecture that integrates two core components: (1) a generative agent "brain," powered by Large Language Models, which interprets natural language commands and acts as an expert educational guide; and (2) a real-time simulation and AR visualization "world," built in the Unity engine for the Meta Quest 3, which renders physically accurate orbital trajectories anchored to the user's environment. The platform facilitates a seamless multimodal interaction loop where a user's voice commands are captured, processed by the agent to alter simulation parameters, and reflected in the AR visualization with conversational auditory feedback. This work delivers a functional prototype that demonstrates a novel approach to science education, transforming abstract data into a manipulable, conversational experience to foster exploratory and deeply engaging learning.
